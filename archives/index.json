[
    {
        "ref": "https://maronghe.github.io/archives/2020/leetcode/523/",
        "title": "523",
        "section": "archives",
        "tags": null,
        "date" : "2020.05.27",
        "body": "// 523. 连续的子数组和 package s // (rem + n*k) % k = rem func checkSubarraySum(nums []int, k int) bool { m := make(map[int]int) m[0] = -1 sum := 0 for i := 0; i \u0026lt; len(nums); i++ { sum += nums[i] if k != 0 { sum = sum % k } if n, ok := m[sum]; ok { if i-n \u0026gt; 1 { return true } } else { m[sum] = i } } return false } https://leetcode-cn.com/problems/continuous-subarray-sum/\n"
    }
,
    {
        "ref": "https://maronghe.github.io/archives/2020/03/15/",
        "title": "#15 二叉搜索树（BST）In Go",
        "section": "archives",
        "tags": null,
        "date" : "2020.04.19",
        "body": " 二叉搜索树（Binary Search Tree In Go）\n ​\t二搜索树叉树特点：\n  极端情况下会退化成链表。\n  中序遍历是递增的。\n  父节点的左孩子都小于父节点，又孩子都大于父节点\n  时间复杂度：\n  Talk is cheap, show me the code\n源码：https://github.com/maronghe/basego/blob/master/ds/binary_search_tree.go\nbinary_search_tree.go\n/* * Copyright (c) 2020 RongHe Ma. * Recording from daily work flow. */ package ds import ( \u0026#34;fmt\u0026#34; ) // BST Node type Node struct { data int count int left *Node right *Node } func NewBinarySearchTree(data int) *Node { return \u0026amp;Node{data, 1, nil, nil} } func (node *Node)Insert(data int) *Node { return _insert(node,data) } func _insert(root *Node, data int) *Node{ if root == nil { return NewBinarySearchTree(data) } if root.data == data { root.count++ } else if root.data \u0026gt; data { root.left = _insert(root.left,data) } else if root.data \u0026lt; data { root.right = _insert(root.right,data) } return root } func (node *Node) Search(data int) *Node { return _search(node,data) } func _search(node *Node, data int) *Node { if node == nil || node.data == data { return node } if node.data \u0026gt; data { return _search(node.left,data) } return _search(node.right,data) } func (node *Node) Delete(data int) *Node { return _delete(node,data) } func _delete(node *Node, data int) *Node { if node == nil { return node } if node.data \u0026gt; data { node.left = _delete(node.left, data) } else if node.data \u0026lt; data { node.right = _delete(node.right, data) } else { // process count \tif node.count \u0026gt; 1 { node.count-- return node } // delete current node \tif node.left == nil { return node.right } if node.right == nil { return node.left } n := _minNode(node.right) node.data = n.data node.right = _delete(node.right,n.data) } return node } func _minNode(node *Node) *Node { for node.left != nil { node = maxNode(node.left) } return node } func maxNode(node *Node) *Node { for node.right != nil { node = maxNode(node.right) } return node } func InOrder(node *Node) { if node != nil { InOrder(node.left) fmt.Printf(\u0026#34;Node{%d count:%d}\\t\u0026#34;, node.data, node.count) InOrder(node.right) } } func PreOrder(node *Node) { if node != nil { fmt.Printf(\u0026#34;Node{%d count:%d}\\t\u0026#34;, node.data, node.count) PreOrder(node.left) PreOrder(node.right) } } func PostOrder(node *Node) { if node != nil { PostOrder(node.left) PostOrder(node.right) fmt.Printf(\u0026#34;Node{%d count:%d}\\t\u0026#34;, node.data, node.count) } } func (node *Node) String() string { return fmt.Sprintf(\u0026#34;Node{data:%d,count:%d,left:%+v,right:%+v}\u0026#34;, node.data, node.count, node.left, node.right) } 单元测试及性能测试代码连接 binary_search_tree_test.go\n 心得\n ​\t写代码切记要有清晰的书写、清晰的布局、清晰的命名，同时还要具备代码的完整性如功能测试、边界测试、负面测试以及性能测试等。\n"
    }
,
    {
        "ref": "https://maronghe.github.io/archives/2020/03/14/",
        "title": "#14 Docker In Hour",
        "section": "archives",
        "tags": null,
        "date" : "2020.04.17",
        "body": " Docker\n 一个统一环境dev/qa/app/beta/cloud的容器、容器是相互隔离的。\nDocker是容器技术，解决软件跨环境的迁移的问题。\nDocker安装后，在本地一守护进程(Daemon)的方式后台运行。\n-\u0026gt; docker -v Docker version 19.03.8, build afacb8b 本地部署的分为image和container，image相当于类，container相当于对象，一个类可以创建多个对象。\nimage 可来自于docker官方Repository Docker Hub 和 private Repository或阿里云镜像 TODO\n镜像命令\ndocker images // 查看当前已安装的镜像列表 docker search [redis] // 搜索redis镜像 docker pull [redis]:[version] // 不指定version默认下载latest docker rmi [imageId]/[redis]:[version] 容器命令\ndocker ps // 查看运行的容器docker ps -a // 查看所有的容器docker -run -it[d] --name=[name] /bin/sh // 运行docker -i持续运行 -t分配终端（交互式） -d后台运行（守护式） /bin/sh mac defaultdocker exec [name] /bin/sh // 进入某一运行的容器中docer [start][stop][rm][inspect] [container-name] // 启动、停止、移除、查看详情数据卷容器\ndocker run -it --name c3 -v /volume centos:latest // 创建名为c3的并带有一个/volume的数据卷容器 centos docker run -it --name c1 --volumes-from c3 centos:latest // 创建c1从c3挂载 docker run -it --name c2 --volumes-from c3 centos:latest // 创建c2从c3挂载  Docker的本质\n  创建新的镜像\n 1.容器转为镜像\ndocker commit 容器id 镜像名字:版本号 docker save -o 压缩文件名称 镜像名字:版本号 docker load -i 压缩文件名称 Dockerfile  FROM centos:latest MAINTAINER maronghe \u0026lt;loganma0209@gmail.com\u0026gt; RUN yum install -y vim # 安装 vim WORKDIR /usr #设置默认目录为/usr CMD /bin/bash docker build -f centos_dockerfile -t logan_centos:0.0.1 .\t// build dockerfile 创建镜像 容器复用宿主机的内核。\n总结：\n"
    }
,
    {
        "ref": "https://maronghe.github.io/archives/2020/03/13/",
        "title": "#13 Go 导包（Import）顺序",
        "section": "archives",
        "tags": null,
        "date" : "2020.04.06",
        "body": "1.包存在哪里？\n​\t看段代码，想必大家都知道GoPath和GoRoot的是什么了。（GoPath = 你的工作空间路径 ，GoRoot = Go的安装路径）\nimport ( . \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; ) func init() { Printf(\u0026#34;Go Root %s \\n\u0026#34;, os.Getenv(\u0026#34;GOROOT\u0026#34;)) // Go Root /usr/local/Cellar/go/1.14/libexec  Printf(\u0026#34;Go Path %s \\n\u0026#34;, os.Getenv(\u0026#34;GOPATH\u0026#34;)) // Go Path /Users/logan/go } 通过 . 对 \u0026ldquo;fmt\u0026rdquo; 进行别名，则不需要使用 fmt.Printf(\u0026quot;...\u0026quot;)了，但一个包中只能有一个.别名否则会报错。同时可以配置多个GoPath用 : 分割，例如 GOPATH=/Users/logan/go:~/myworkspace\n2.扫描包的顺序？\nimport ( \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; ) 如果搜索net/http包时，搜索顺序如下:\n/usr/local/Cellar/go/1.14/libexec/src/net/http /Users/logan/go/src/net/http ~/myworkspace/src/net/http 3.包的导入顺序？及var、const、init()加载顺序。\n包导入顺序如图所示，同时可知先初始化const、其次为var、之后为init()，注意同时可以有多个init方法，从上到下依次执行。\n4.包重名了怎么办？\nimport ( \u0026#34;runtime\u0026#34; \u0026#34;strings\u0026#34; strings2 \u0026#34;strings\u0026#34; \u0026#34;testing\u0026#34; ) func TestImport(t *testing.T){ strings.PrintlnHello(\u0026#34;Logan\u0026#34;) strings2.Compare(\u0026#34;a\u0026#34;,\u0026#34;b\u0026#34;) } 如果包重名了，只能起别名，否则不能识别出是哪个包中的方法需要引用。\n5.包导入的”奇淫技巧“\n​\t_导入 及 远程包\n_ \u0026#34;github.com/go-sql-driver/mysql\u0026#34; // 导入mysql驱动 仅需要依赖执行github.com/go-sql-driver/mysql中的初始化init()函数\n编译期加载  var ( // 常量，数值、字符(runes)、字符串或布尔值等 \ti = 1\u0026lt;\u0026lt;3 ) 运行期加载，如：  math.Sin(math.Pi/4)  参考连接：\n https://www.cnblogs.com/f-ck-need-u/p/9847554.html  "
    }
,
    {
        "ref": "https://maronghe.github.io/archives/2020/03/11/",
        "title": "#11 Session与Cookie的区别",
        "section": "archives",
        "tags": null,
        "date" : "2020.04.06",
        "body": " Session 和 Cookie 看法\n 首先HTTP协议是无状态的，当我们开发的一些对状态有要求的接口时，Cookie和Session弥补了这一块的能力。\nCookie\n  对于HTTP协议来说，Cookie只是请求头中的一个字段且与其他字段没什么区别。\n  浏览器对Cookie做了默认的支持并限制了Cookie的[同源策略]，即同域才能访问Cookie的内容。\n如当我们做SSO（单点登录），一般可以把Cookie种在可访问的一级域名下。\n  Session\n  Session是服务器为每个Web用户分配的独立状态存储空间。\n若用户的数据存放在存在某个单点服务器上时，当以七层或四层转发时，请求到后端集群的时候，就存在Session命中的问题（分布式Session问题），这时候需要有中心的方式去统一管理Session，比如存储在DB或缓存中。\n  SessionID：可以由标准OAuth 2.0 来实现最终换取 token 即 sessionId ，并持有过期时间自动刷新逻辑。\n  总结：\n​\tCookie 和 Session 都是辅助HTTP协议无状态性产生的。\n"
    }
,
    {
        "ref": "https://maronghe.github.io/archives/2020/03/2/",
        "title": "#2 [采坑指南] json.Unmarshal后interface{}成map[string]interface{}",
        "section": "archives",
        "tags": null,
        "date" : "2020.03.29",
        "body": "​\t可能大家工作中都会遇到类型断言，即接口类型断言是否为某种strcut类型i.(A)或某种struct的指针类型i.(*A)。\n那么当一个想要一个interface{}类型既想转换成多种类型，且多种类型并不属于同一种。这句话说的可能比较绕圈，下面举个例子来看下。\n当有两个SA和SB，当我们想要从字符串翻转成结构体时。我们可以\n没问题，输出结果是\nsa {logan 18 Beijing} PASS 但是当结构体内容时由其他结构体，以interface{}类型进行返回时，那么情景可能如下。\n如果50和51行都注释掉了的话，那么结果会输出\nit2 data type is map[string]interface {} ti3 type assertion error, it isn't type SA ti4 type assertion error, it isn't type SB ti5 is map[addr:Beijing age:18 name:logan] PASS 意味着data转换成了map[string]interface{}如果转换成map[string]interface{}类型后，那么想要key中的value还需要继续类型断言。\n为什么会转成map[string]interface{}呢？因为对象底层类型，当unmarshal时并不知道对象底层类型。\n那么，是否有一种希望转成的类型当我们的确希望转换成某种类型，如SA或SB。\n答案是需要告诉结构类型的底层类型是什么，才可做此类型的类型断言。\n解开注释50或51行后，则输出结果成为\nit2 data type is *main.SB ti3 type assertion error, it isn't type SA ti4 is \u0026amp;{logan 18 } ti5 type assertion error, it isn't type map[string]interface{} PASS 总结：当我们希望类型断言的结构体中是一个interface{}类型时，希望转换成某种我们希望的类型，要进行底层类型的转换。那么就要给Data进行赋值类型。则断言方可成功。\n 参考内容\n  https://github.com/maronghe/todo-list/issues/5 https://stackoverflow.com/questions/43325288/golang-convert-interface-to-struct/43325450 https://play.golang.org/p/6fOr0rFV_e1  "
    }
,
    {
        "ref": "https://maronghe.github.io/archives/2020/03/1/",
        "title": "#1 第一篇博客 \u0026 回顾我的大学",
        "section": "archives",
        "tags": null,
        "date" : "2020.03.22",
        "body": "​\t2020年3月21日晚，参加了Go夜读两周年的回顾。也是第82期的Go夜读share。虽然加入这个大家庭才不长时间，学习Golang这门语言也不是很久，因为之前做Java相关的工作。后期因为组织架构调整，公司要用Go去重写Java的服务，正因为如此，好些人都去转Go或离职。我也踏上了学习Golang的旅程。\n 自述大学\n ​\t我的大学专业是IOT，也就是物联网工程，一个软硬件都需要掌握的一个专业，我也相信是未来的趋势。但我从事了软件开发行业，也不知道算不算上所谓的”科班出身“。\n​\t大学大一度过的很”轻松加愉快“，仅参加了学校的《舞蹈社》（很奇怪，为什么一个Coder会参加舞蹈社，这可能与上高中之前的认知比较少有关吧，暂不讨论）。相反学习Software的知识比较少。\n​\t大二的我知道毕业时不能以在大学玩得好才能找到一份好工作的。后来经过我的DB老师的指导，自学了Java、JSP，记得当时大二的寒假，跟着老师去图书馆借了一本JSP相关的书籍，回家“啃”了起来。殊不知对于一个高中贪玩，大学以为“解放”了自己的我来说，啃书是多么的痛苦。正如我所料，我的进度比较慢，相当于把一本书分了40多份，每份是一天的消化的量。看完即完成了任务。这也是我自学之路的一个开始，但如今的我深知，如果自学都学不会的话，也不适合做Coder相关的工作。下学习又学了Java，DB等，但是看起来都只是学了个表面。\n​\t大三跟着老师做了个项目，名为《在线考试系统》，可想而知，在线考试系统即为学校教师出题，学生答题等一系列的相关的操作。这个项目做起来，很多的是在写业务，写逻辑。对于Spring原理来讲根本就没去了解。当时只记得一句话，‘在出校门的时候，自己有项目经历和没有项目经历完全是不一样的’。所以，乐此不疲的把这个项目做来做去。最终主要的功能也都做完了。相反，自己的DB底层原理，数据结构及算法和框架原理性的知识都被忽略了。后期才知道，毕业的春招和秋招对于应届生来讲，就考的是算法和数据结构和一些底层的原理知识。那么我一年多都是白干了么？不会吧？可能吧。不后悔不怪罪，这也是一个人渐渐成熟的体现吧。\n​\t大四有的同学继续考研，有的去找工作。我就是陷入了找工作的道路上。记得面试了20天左右。一个offer都没有收到，也正是我在家里的时候，IBM人力资源部给我打电话邀请我参加面试。我遍立刻答应了。一想IBM是外企大厂，以后说出去也有面子（当时无知的我）。可惜只是一个边缘部门吧。没学到什么知识，只了解的外企的文化（不加班就是个最大的特点）。所以，我觉得不能无为了，遍自学起了Java原理、设计模式、DB底层结构、Hadoop（HDFS、MapReduce）等。每日坚持9点去上班，23点才下班让的决心（当时我正式上班时间为下午2点到晚上11点，也腾出很多自学的时间）。后来请假去北京面试一周，最后也是来到了现在的公司，工作至今。\n 未来的展望和建议\n ​\t最后，想说这路上自己的认知发生的不断的变化。眼光看的也越来越长远了起来。想建议未来的我和其他的人，要把眼光放长远了。自己的路只能自己走，不要想着依赖谁，不要做“拿来党”，每个人都是时间都是有限的，不要辜负年轻时的自己。趁着年轻，多折腾折腾。\n2020-03-22 18:07:13 于北京 马荣贺 Logan Ma\n"
    }
,
    {
        "ref": "https://maronghe.github.io/archives/2020/03/10/",
        "title": "",
        "section": "archives",
        "tags": null,
        "date" : "0001.01.01",
        "body": "title: \u0026ldquo;#10 Study Recording\u0026rdquo; date: 2020-04-3T12:39:01+08:00 draft: true\n   Q : 怎样知道一个变量分配到堆上还是栈上？\nA :编译器首先尝试分配到栈上，但如果编译器不能保证函数返回值是否被引用，那么编译器会分配到堆上。如果一个对象太大了。也会分配到GC堆上。当今的编译器来说，如果一个使用变量的地址，该对象时分配堆上的候选对象，但是逃逸分析后可以识别如果改对象未超过函数的返回范围，那么该变量也可能保存在栈上\nR : https://golang.org/doc/faq#stack_or_heap\n  new 和 make 有什么区别\nA : new(T)： 分配内存 但初始化仅为0值并返回其指针T和*T（值）。\n​\tnew(File) =\u0026gt; \u0026amp;File{} // 初始化0值\n​\tmake(T,args) 仅用于创建 map slice channel，并返回非0值（not zeroed）的类型T（非 *T）\nR : https://golang.org/doc/effective_go.html#allocation_new\n​\thttps://golang.org/doc/effective_go.html#allocation_make\n  Go 的内存分配器是基于TCMalloc的一种分配器（TC Malloc Thread-Cached Malloc）\n​\tYouTube Link, GopherCon UK 2018\n 申请内存顺序    4.Go是一种基于epoll的多路复用IO模型，其TCPListener是对netFD进行封装。\n Sudog的资源池：每个P都有自己的缓冲池和全局调度器缓存池。\n 当本地的sudog的缓冲区为0时，加锁去全局调度器sudog的缓冲池去取全局的一半。 否则新创建一个sudog。    go语言编译后成汇编语言。\ngo tool compile -S file.go\n  "
    }
,
    {
        "ref": "https://maronghe.github.io/archives/2020/03/18/",
        "title": "",
        "section": "archives",
        "tags": null,
        "date" : "0001.01.01",
        "body": "创建路径/data本地：\nmkdir -p /Users/logan/dev/workspace/mysql-docker/data3307\nmkdir -p /Users/logan/dev/workspace/mysql-docker/data3308\n创建配置文件：\nvim /Users/logan/dev/workspace/mysql-docker/my3307.cnf\n# msyql 3307的配置： [mysqld] pid-file\t= /var/run/mysqld/mysqld.pid socket\t= /var/run/mysqld/mysqld.sock datadir\t= /var/lib/mysql server-id = 1 log_bin = mysql-bin binlog_format = ROW expire_logs_days = 30 vim /Users/logan/dev/workspace/mysql-docker/my3308.cnf\n# msyql 3308的配置： [mysqld] pid-file\t= /var/run/mysqld/mysqld.pid socket\t= /var/run/mysqld/mysqld.sock datadir\t= /var/lib/mysql server-id = 2 log_bin = mysql-bin binlog_format = ROW expire_logs_days = 30 创建容器：\ndocker run -d -p 3308:3306 -v /Users/logan/dev/workspace/mysql-docker/my3308.cnf:/etc/mysql/mysql.conf.d/mysqld.cnf -v /Users/logan/dev/workspace/mysql-docker/data3308:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 --name mysql-3308 mysql:5.7 docker run -d -p 3307:3306 -v /Users/logan/dev/workspace/mysql-docker/my3307.cnf:/etc/mysql/mysql.conf.d/mysqld.cnf -v /Users/logan/dev/workspace/mysql-docker/data3307:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 --name mysql-3307 mysql:5.7 连接客户端（创建表）：\nmysql -uroot -h 127.0.0.1 -P3307 -p123456 create database test; use test; create table user ( id int, name varchar(10), score int ); insert into user values(1, \u0026#34;foo\u0026#34;, 10); exit; mysql -uroot -h 127.0.0.1 -P3308 -p123456 create database test; use test; create table wallet ( id int, money float ); insert into wallet values(1, 10.1); 奇怪的问题：当启动一个XA事务的时候，一直阻塞在执行任务的命令上。\n随后查阅资料，\nSELECT * FROM `information_schema`.`innodb_trx` ORDER BY `trx_started`; 发现有正在进行中的事务，但是kill不掉，recover xa; 看到有为提交的xaid。\n`xa commit 1587995602;\n提交后之后就好了。\n"
    }
,
    {
        "ref": "https://maronghe.github.io/archives/2020/03/19/",
        "title": "",
        "section": "archives",
        "tags": null,
        "date" : "0001.01.01",
        "body": "docker run --name myredis -p 6380:6379 -d -v /Users/logan/dev/workspace/redis-docker:/data redis:latest --appendonly yes .... 127.0.0.1:6380\u0026gt; zadd zlist 128 hhhh (integer) 1 127.0.0.1:6380\u0026gt; object encoding zlist \u0026#34;ziplist\u0026#34; 127.0.0.1:6380\u0026gt; ZCARD zlist (integer) 128 127.0.0.1:6380\u0026gt; zadd zlist 140 hqhhh (integer) 1 127.0.0.1:6380\u0026gt; object encoding zlist \u0026#34;skiplist\u0026#34; 127.0.0.1:6380\u0026gt; ZCARD zlist (integer) 129 .... 结论，超过128之后或超过单node64字节就会变成skiplist 那么在128内是ziplist的，但是在129以后就会变成skiplist以平均Log(N)的（最坏O(n)）时间复杂度查询。 Q：\n 为什么ziplist可以节省空间？以一种时间换空间的思想。 String (int ,embstr,row) List (ziplist, linkedlist) Hash (ziplist, hashtable) Set (inset, hashtable) Zset (ziplist, skiplist)  "
    }
,
    {
        "ref": "https://maronghe.github.io/archives/2020/03/20/",
        "title": "",
        "section": "archives",
        "tags": null,
        "date" : "0001.01.01",
        "body": "DIstributed Cron Job In Micor\n定时任务几乎在所有的项目后台存在，可能在特定是时间执行一次或周期性的执行。\n 单机\n ​\t在单机中的服务中，一般定时任务是直截了当和简单的。\n但是在多节点中的定时任务，通常可能有===任务重复执行和单点故障问题===。\n1.一些’伙计‘将定时任务从守护进程中移到Web服务中并暴露API或RPC接口，然后触发器通过操作系统执行任务。或通过负载均衡，去请求一个节点。但是还是有单点故障问题。\n但是还是能同时解决 重复执行 和 单点故障问题。这正是面临的经典问题 ： Leader选举。\nMicor 可以创建定时任务\n// get etcd node list from registry  etcdList := service.Options().Registry.Options().Addrs // build leader  lead := etcd.NewLeader(leader.Nodes(etcdList...)) cron := sync.NewCron(sync.WithLeader(lead)) cron.Schedule( task.Schedule{Interval: 10 * time.Second}, task.Command{Name: \u0026#34;foo\u0026#34;, Func: func() error { log.Info(\u0026#34;finish command foo\u0026#34;) return nil }}, ) Note： 其依赖 Etcd、zookeeper等分布式选举中间件。其实之前自己实现的通过Redis实现的分布式锁的逻辑，也是一个自我周期性获取Heath Check 和 抢占获取锁（选举当Leader）的过程。\ntask.Schedule =\u0026gt; 就两个内容 -\u0026gt; // Schedule represents a time or interval at which a task should run type Schedule struct { // When to start the schedule. Zero time means immediately  Time time.Time // Non zero interval dictates an ongoing schedule  Interval time.Duration }  服务熔断和限流\n hystrix \u0026amp; gobreaker\n插件帮我们解决：\nDefaultMaxConcurrent 是对于三个服务还还是3个不同的方法呢？\nhttps://github.com/micro/go-plugins/blob/master/wrapper/breaker/hystrix/hystrix.go\nfunc (c *clientWrapper) Call(ctx context.Context, req client.Request, rsp interface{}, opts ...client.CallOption) error { return hystrix.Do(req.Service()+\u0026#34;.\u0026#34;+req.Endpoint(), func() error { return c.Client.Call(ctx, req, rsp, opts...) }, nil) } ... hystrix.ConfigureCommand(\u0026#34;com.serviceA.methodFoo\u0026#34;, hystrix.CommandConfig{ MaxConcurrentRequests: 50, // 最大并发请求数 每个服务每个节点的每个方法  Timeout: 10, // 超时时间  }) hystrix.ConfigureCommand(\u0026#34;com.serviceB.methodBar\u0026#34;, hystrix.CommandConfig{ Timeout: 60, }) ... // req.Service()+\u0026#34;.\u0026#34;+req.Endpoint() 意味着服务和端点，并没有管节点的数量， // so : each method of each service counts independently and does not affect each other. // 每个服务的每个方法数量的限制，并不影响其他的。  Rate Limiter\npackage main import ( limiter \u0026#34;github.com/micro/go-plugins/wrapper/ratelimiter/uber/v2\u0026#34; ) func main() { const QPS = 100 // New Service  service := micro.NewService( micro.Name(\u0026#34;com.foo.srv.hello\u0026#34;), micro.Version(\u0026#34;latest\u0026#34;), micro.WrapHandler(limiter.NewHandlerWrapper(QPS)), // 限制接口最大并发数  ) } Final Worlds :\nThe role of Circuit Breaker is to protect the client from being dragged down by external service issues and always respond quickly (even if you get an error, it is better than waiting for a long time). Always avoid excessive consumption of resources (避免过度消耗资源).\nWhile the role of Rate Limiter is to protect the server. Only handle the traffic within its capacity to achieve overload protection. An error is returned immediately when the traffic exceeds the preset limit.\n ZooKeeper （借鉴于文件系统）\n  Zookeeper 用于 分布式 系统中协调任务。 任务可以是协作的（主给从分配任务）、也可以是竞争关系（竞争主节点争取执行权，实现互斥排他锁）。 特性：  保证CAP中的CP（即强一致性，持久性（分区容错和顺序性）） 实现通用的同步原语能力？？？ 提供简单的并发处理机制    Zookeeper :\n setup /conf/zoo.cfg file. include port、dataDir、tickTime and so on. bin/zkServer.sh start  start a server. bin/zkCli.sh -server 127.0.0.1:2181 connect the local zk server. \u0026hellip; ls / , create /my_zk hello , set /my_zk world , delete /my_zk \u0026hellip; For more detail. 强烈建议zk集群节点为奇数，否则无法完成节点选取。（大于一半以上同意才能当成leader） Finally, note the two port numbers after each server name: \u0026quot; 2888\u0026rdquo; and \u0026ldquo;3888\u0026rdquo;. Peers use the former port to connect to other peers. Such a connection is necessary so that peers can communicate, for example, to agree upon the order of updates. More specifically, a ZooKeeper server uses this port to connect followers to the leader. When a new leader arises, a follower opens a TCP connection to the leader using this port. Because the default leader election also uses TCP, we currently require another port for leader election. This is the second port in the server entry. 最后我们注意到有每个server都有两个端口号，端口对等使用。若需要保证一个必要的连接，以至于对等方可以通信。例如同意更新顺序，更特别的是，一个zk sever使用一个端口连接followers到leader。当一个新leader成立之后，一个从节点打开一个TCP连接到leader使用这个端口。因为leader的选举也是用过TCP，我们要求leader选举另外一个端口号，这就是第二个端口号在server entry中。 总结一句话， 从节点一个端口用于连接TCP连接与主节点，当阶段选举时，也要用过端口使用TCP进行选举。  分布式锁中重要的特性之一是，如果节点获取锁后当Carsh后必须释放锁。\nzookeeper 可以用过 create -e /lock 's2:2228'创建临时节点去加锁，正是利用了当session断开后，连接自动被删除的特性实现。同时，可以通过watch命令进行查看状态并监听state -w /lock，如果监听的节点断开后，会通知到监听节点一个event节点被删除的事件。\n  myid file is missing：\n需要在dataDir下创建myid文件并且需要在里面指定当前版本1\nzk 分布式锁，\n使用临时顺序节点\n创建最小后缀数字znode的用户获取到锁。\n避免羊群效应。\nwatch前一个节点的状态，此锁还能遵循公平原则。先到的锁请求先处理。仅通知一个锁的等待者。避免通知所有。\n2 watch 1 , 3 watch 2\n  ./bin/zkCli.sh -server 127.0.0.1:2181,127.0.0.1:2182,127.0.0.1:2183\n随机选取一个节点连接。\n如果节点A（非住检点）宕机后，则客户端会收到一个事件(Event ， Closing Socket Exception)，则会从其他节点中选取一个进行连接。\n如果一个主节点宕机之后从节点由于连接不上主节点之后会在仲裁模（Quorum）式下进行leader选举\n2020-05-14 17:05:20,780 [myid:3] - INFO [QuorumPeer[myid=3](plain=[0:0:0:0:0:0:0:0]:2183)(secure=disabled):ZooKeeperServer@329] - Created server with tickTime 2000 minSessionTimeout 4000 maxSessionTimeout 40000 clientPortListenBacklog -1 datadir /Users/logan/Documents/env/zookeeper3/data/version-2 snapdir /Users/logan/Documents/env/zookeeper3/data/version-2 2020-05-14 17:05:20,782 [myid:3] - INFO [QuorumPeer[myid=3](plain=[0:0:0:0:0:0:0:0]:2183)(secure=disabled):Leader@581] - LEADING - LEADER ELECTION TOOK - 221 MS 2020-05-14 17:05:20,783 [myid:3] - INFO [QuorumPeer[myid=3](plain=[0:0:0:0:0:0:0:0]:2183)(secure=disabled):QuorumPeer@863] - Peer state changed: leading - discovery 2020-05-14 17:05:20,784 [myid:3] - INFO [QuorumPeer[myid=3](plain=[0:0:0:0:0:0:0:0]:2183)(secure=disabled):FileTxnSnapLog@470] - Snapshotting: 0x900000007 to /Users/logan/Documents/env/zookeeper3/data/version-2/snapshot.900000007 2020-05-14 17:05:20,784 [myid:3] - INFO [QuorumPeer[myid=3](plain=[0:0:0:0:0:0:0:0]:2183)(secure=disabled):ZooKeeperServer@519] - Snapshot taken in 1 ms 2020-05-14 17:05:20,889 [myid:3] - INFO [LearnerHandler-/127.0.0.1:59479:LearnerHandler@504] - Follower sid: 1 : info : 127.0.0.1:2777:3777:participant 2020-05-14 17:05:20,891 [myid:3] - INFO [LearnerHandler-/127.0.0.1:59479:ZKDatabase@345] - On disk txn sync enabled with snapshotSizeFactor 0.33 2020-05-14 17:05:20,892 [myid:3] - INFO [LearnerHandler-/127.0.0.1:59479:LearnerHandler@800] - Synchronizing with Learner sid: 1 maxCommittedLog=0x900000007 minCommittedLog=0x900000001 lastProcessedZxid=0x900000007 peerLastZxid=0x900000007 2020-05-14 17:05:20,892 [myid:3] - INFO [LearnerHandler-/127.0.0.1:59479:LearnerHandler@845] - Sending DIFF zxid=0x900000007 for peer sid: 1 2020-05-14 17:05:20,892 [myid:3] - INFO [QuorumPeer[myid=3](plain=[0:0:0:0:0:0:0:0]:2183)(secure=disabled):QuorumPeer@863] - Peer state changed: leading - synchronization 2020-05-14 17:05:20,897 [myid:3] - INFO [QuorumPeer[myid=3](plain=[0:0:0:0:0:0:0:0]:2183)(secure=disabled):Leader@1501] - Have quorum of supporters, sids: [[1, 3],[1, 3]]; starting up and setting last processed zxid: 0xa00000000 2020-05-14 17:05:20,898 [myid:3] - INFO [QuorumPeer[myid=3](plain=[0:0:0:0:0:0:0:0]:2183)(secure=disabled):CommitProcessor@476] - Configuring CommitProcessor with readBatchSize -1 commitBatchSize 1 2020-05-14 17:05:20,899 [myid:3] - INFO [QuorumPeer[myid=3](plain=[0:0:0:0:0:0:0:0]:2183)(secure=disabled):CommitProcessor@438] - Configuring CommitProcessor with 12 worker threads. 2020-05-14 17:05:20,906 [myid:3] - INFO [QuorumPeer[myid=3](plain=[0:0:0:0:0:0:0:0]:2183)(secure=disabled):ContainerManager@83] - Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 2020-05-14 17:05:20,908 [myid:3] - INFO [QuorumPeer[myid=3](plain=[0:0:0:0:0:0:0:0]:2183)(secure=disabled):QuorumPeer@863] - Peer state changed: leading - broadcast dataTree 保存在内容中 8G It fine.\nCPU不是性能的瓶颈，所以双核CPU就可以。存储设备的写延迟会直接影响事务的提交效率。所以建议分配一个独立的dataLogDir的SSD磁盘。\n// zk监控 JMS + Prometheus\n// Observe 实现 zk 跨区域部署，优化节点响应速度。 发送 forward 的等待 infor\n节点间的 propose、ack、commit消息跨区域\n动态配置：dynamic configuration\n服务发现 服务实例获取 服务反馈（Curator） etcd k8s 服务发现 和 配置中心 OpenStack 配置中心 和 分布式锁 ROOK 编排引擎 zk datatree 需要加载到内存 几百兆 etcd bbolt 存储引擎 几个GB k-v 存储 MVCC compaction reversion 进行整理和清除之前的版本 bbolt -\u0026gt; b+ tree key : major + sub + type 1.major -\u0026gt; reversion 2.sub -\u0026gt; 每次更新的key 3.type 保存可选项的特殊值 （11 22 平台） 内存中还维护了一个btree，是key-value 中的 key LSM Log Struct Merge-Tree B+ Tree And Compare with B+ Tre and LSM // 1 简历与要求要高度匹配\n// 2 体现自己能干活\n// 3 体现自己非常愿意以正式员工并长久的留在大厂工作\n TODO\n  基于Kubernetes的CICD的环境部署实施   Slice扩容规则\n1.预估扩容后的容量 newCap -\u0026gt; 预估元素个数\n​\t如果 扩容前容量翻倍还是小于最小长度，那么就等于最小长度 oldCap * 2 \u0026lt; cap， newCap = cap\n​\t否则 如果扩容前长度(oldCap)小于1024 则 newCap = oldCap * 2\n​\t否则 \u0010\u0010\u0010\u0010\u0010 \u0026gt;= 1024 则 扩容1/4 newCap = oldCap * 1.25\n2.newCap个元素需多大内存？（与元素类型大小挂钩）\n​\tnewCap * 元素大小 = 所需内存大小（并非直接向操作系统申请内存，与各语言内存管理模块有关）\n匹配合适的内存规格。Go内管理模块分为：8 ，16，32，48，64，80，96，112\u0026hellip;.  ​\t如 我要申请24字节内存，则 Go直接分配 32 字节内存。（匹配足够大且最接近的规格）\n s := []int{1, 2} // int 8 字节 s = append(s, 3, 4, 5) // step 1 3 * 2 = 6 // 5 \u0026gt; 4 = 5 // 5 * 8 = 40 \u0026lt;= 48 // 48 / 8 = 6 fmt.Println(len(s)) // 5 fmt.Println(cap(s)) // 6 fmt.Printf(\u0026quot;%p\\n\u0026quot;, s) // 0xc00001c180 s = append(s, 6) fmt.Printf(\u0026quot;%p\\n\u0026quot;, s) // 0xc00001c180 fmt.Println(len(s)) // 6 fmt.Println(cap(s)) // 6 a := []string{\u0026quot;my\u0026quot;,\u0026quot;name\u0026quot;,\u0026quot;is\u0026quot;} // 64位 16字节 a = append(a,\u0026quot;Logan\u0026quot;) // 3 * 2 \u0026gt; 4 , newCap = 6 // 16 * 6 = 96 字节 // newCap = 16 迁移不是从cell 0位置开始迁移的\n"
    }
,
    {
        "ref": "https://maronghe.github.io/archives/2020/03/21/",
        "title": "",
        "section": "archives",
        "tags": null,
        "date" : "0001.01.01",
        "body": "8根 地址总线只有八位 即 1字节 【0,255】 256 是8根地址总线的最大寻址空间\n32根 32位 4G 最大寻址空间\n每次操作4字节 （机器字长）就需要32位数据总线\n​ 8字节 64位\n内存并行访问 提高响应速度。得到逻辑连续内存。\n若想从 1 字节读取8个字节。CPU额外处理先读1-7 + 8 ，读取两次，会影响性能。\n所以编译器会把各种类型放在合适的地址、合适的长度。-》 内存对齐。\n每个类型都会有一个对应的 对齐边界。（要求数据存储地址，以及占用的字节数，都要是对其边界的倍数）\nInt16 2 字节\nInt32 4 字节\n不同平台对齐边界不同。**数据类型对其边界 = min（类型大小，平台最大对齐边界）\n为什么不采用 平台最大对齐边界或采用类型大小呢？\n原因：1.内存浪费 或\n​\t2.读取两次进行拼接\n 3. 内存浪费更少，（32位 4 字节 存储 int64）如下图所示。 4. ![](https://tva1.sinaimg.cn/large/007S8ZIlly1geyzbrdlk9j30lh0dqgn2.jpg)  结构体 内存对齐边界，取结构体中最大的类型对齐值，取最大的。\n要求1：\n1.\t存储结构体地址，是对齐边界的倍数。 2.\t存储地址addr ，当成地址0，然后用相对地址 计算自己的位置应当放在哪。  如果内存未对齐，\n​\t1.内存浪费\n​\t2.读取两次进行拼接\n结构体的大小保证是内存对齐的整数倍之后，才能保证数组中每个都是内存对齐的。\n结构体如果补充过大的话，就可能会重新内存对齐。以节省空间。\nint 是在不同的操作系统上占用的长度不一样，\n64位系统中按照 int64\n32位按照 int 32\n"
    }
,
    {
        "ref": "https://maronghe.github.io/archives/2020/03/https/",
        "title": "",
        "section": "archives",
        "tags": null,
        "date" : "0001.01.01",
        "body": "前端工程化 HTTP 2.0 HTTPs HTTP 1.0 1.1\n1.1\n// HTTPs = HTTP + SSL\nHTTP 2.0\n 首部压缩 多路复用 二进制分帧 服务端推送  cookie header -》 20\nok 2 byte\n22 = 2 + 20\n​ http 1.1\nclient \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash; server\nhttp -\u0026gt; tcp\ntcp 3 4\n1.0 短连接\n1.1 长链接 connection = keep-alive\nConnect\n1 - \u0026gt;\n\u0026lt;\u0026ndash;\n-\u0026gt;\n\u0026lt;-\n..\nclose\n1.1\nheader + cookie 20\nbody = 2\n\u0026mdash;\u0026gt; 占网络带宽 -\u0026gt;\n2 / 22\nHeader 压缩\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n  首部压缩 服务端推送   index.html\nindex.js\nindex.css\n2.0\nIndex.html \u0026lt;\u0026mdash;- index.js\n​ \u0026lt;\u0026mdash;- index.css\n![image-20200524113116006](/Users/logan/Library/Application Support/typora-user-images/image-20200524113116006.png)\nhttp server\nClient Server\ndata \u0026mdash;\u0026ndash; \u0026gt; (data) \u0026mdash;- \u0026gt; data\n对称加密的秘钥 abc\ndata + abc -\u0026gt; 291j39hcfwqj \u0026mdash;\u0026mdash;\u0026mdash;\u0026gt; 291j39hcfwqj \u0026mdash;\u0026mdash;\u0026raquo;\u0026gt; 291j39hcfwqj + abc = \u0026gt; data 加密、解密\nclient -\u0026gt; server\nserver create 秘钥abc -\u0026gt;\nclient \u0026lt; \u0026mdash;- 秘钥abc \u0026mdash;- server\n非对称加密\n「 public a 、 private a 」 data + public a =\u0026gt; 2n31fuuqn1nf\n2n31fuuqn1nf + private a \u0026mdash;\u0026gt; data\nabc ——》 abc -————》 abc 非对称加密\ntcp 消耗内存 2K 4G\nN Request - \u0026gt; N tcp\n     1 tcp -\u0026gt; M request\nTODO\nhttp 1.0 1.1有证书么？\n"
    }
,
    {
        "ref": "https://maronghe.github.io/archives/2020/03/lx/",
        "title": "",
        "section": "archives",
        "tags": null,
        "date" : "0001.01.01",
        "body": "项目启动\nmain.go -\u0026gt; 1.初始化qLog （日志地址、队列大小、并发标识、最小日志级别） 2.init etcd 3. init infra-components ？ 4.init project config（cmd -\u0026gt; etcd -\u0026gt; default） openHost、appHost、authHost app白名单（redirect、cors） init router -\u0026gt; pathPrefix/api/v1 和 allowOrigin （可信域名） init mongo、mysql、redis、crontab、openLog、s3等 https 需要配置 tls证书和tls私钥 数据存储\n8 bit -\u0026gt; 1 byte (0xab) // 8位 = 1字节 short 16 bit -\u0026gt; 2 byte int 32 bite -\u0026gt; 4 byte int64 64 bite -\u0026gt; 8 byte  并发、并行\n  单核CPU中每个任务通过时间片或主动让出执行权来实现业务切换。（并发） 多核CPU在一个进程中使多个线程并行同时运行，达到并行。   进程、线程、携程\n  进程是操作系统的资源分配的基本单位，有独立运行空间。 线程是CPU调度基本单位，线程依附于进程存在，并共享父进程的资源。 协程是用户态的轻量级线程，协程的调度完全是用户控制，其切换时不需要进入内核切换，所以无内核开销。   线程上下文切换\n ​\t上下文切换代价是昂贵的，在CPU上交换线程会花费很多时间。延迟在50-100us之间，硬件平均在每个核心上执行是12op/us所以一次切换可能会花费600-1200指令延迟。\n 工作窃取\n 本地-\u0026gt; (为空时)全局-\u0026gt; 本地 ( WSS )\n 减少阻塞\n   由于Atomic、Mutex、Channel等导致GoRoutine阻塞\n调度器把当前的G切换出去，重新安排LRQ的其他GoRoutine。\n  由于网络请求或IO操作导致G阻塞。\nGo提供了NetPoller（网络轮询器）来处理网络请求和网络IO问题，通过epoll来实现多路复用。\n将G放入NetPoller队列中，避免创建新M，G再放回LRQ中等待执行。\n  syscall时（无法使用NetPoller）而进行系统调用的GoRoutine阻塞了当前的M\n1.13之前G和M会绑定（IO同步调用阻塞M），将M与P分离，同时也将G带走，然后调度器引入新的M2和来服务P，此时LRQ中继续执行G。阻塞后G1可以移回LRQ，M1以待重复使用。\n  GoRoutine执行Sleep导致M阻塞\n将G放入Timer等待队列中，继续执行LRQ的下一个G。等待执行契机放入LRQ执行。\n  "
    }
,
    {
        "ref": "https://maronghe.github.io/archives/2020/03/untitled/",
        "title": "",
        "section": "archives",
        "tags": null,
        "date" : "0001.01.01",
        "body": " 自我介绍\n ​\t莫愁前方无知己，天下谁人不识君。\n​\t面试官您好，我叫马荣贺，毕业于\u0026hellip;\u0026hellip;..，目前就职于蓝信移动有限公司，从事服务端研发相关的工作。工作日常负责项目的评审、研发及后期的维护。\n​\t学习就要有节奏，有方向的进行。给自己顶一个短期计划，如三天，一周，半个月等。不能为了面试而学习这样只会让自己在临近工作做不下去，或想找工作之气临时抱佛脚。游戏切记成瘾！\n​\t学习是要有自我分析理解的过程，看网上的某些教程视频，人家仅会给你他理解到的内容，可能会有些不准确，也可能会有些偏差，当他给你讲述的同时，你可能理解有偏差。这样的话，你与其他人交流时，由于没有自己分析和摸索知识的过程，会显得格外的“虚”，不懂原理，不知其所以然。\n​\t所以学习还是要通过自己的一点一滴积累，寻求权威的认证，最不断地求知精神。同样在生活中多应该问问自己：“为什么？”，为什么这样做就可以，多思考，多探索。学习后要有些输出如博客等。也可以与组内和朋友交流，如果你能给其他人以通俗易懂的方式讲明白了。那么就证明你明白了。\n​\t分析问题的过程：\n  为什么这么做？\n  解决了哪些问题？\n  逻辑和技术难点？\n  自己做出了哪些事情？\n如：『原因』系统为了解决用户的客户端APP连接会话不在线，同样可以将消息发送到对方手机上。「解决方案」从而引入了手机厂商的Push服务，可在用户登录时，端上调用手机厂商提供的结构，创建自己的手机的设备Token，将Token上传到自己的Server去维护。则服务端在发消息的同时可确定是否要发送系统Push来通知用户客户端。「性能提升」通过Push的接口的性能测试，可判别出Push服务的性能，从而发现性能瓶颈，解决和优化。\n   计算机组成原理 操作系统 数据结构与算法 计算机网络（） 数据库原理 Go语言实现原理及新特性 Docker、K8S容器化、Service Mesh Redis、Kafka、ZK、ES、Nginx、Kibana、jenkins中间件 分布式、RPC、微服务链路追踪 网络安全攻击 性能测试 自定义协议  "
    }
,
    {
        "ref": "https://maronghe.github.io/archives/2020/leetcode/go/",
        "title": "",
        "section": "archives",
        "tags": null,
        "date" : "0001.01.01",
        "body": "Go 调度器\n  线程池的缺陷\nG -\u0026gt; Create -\u0026gt; Pool -\u0026gt; G(Block) -\u0026gt; Pool !增大! -\u0026gt; Thread ! -\u0026gt; CPU竞争 -\u0026gt;消费能力有上限 或 下降\n  Go中为了大量线程进行CPU竞争从而自己实现调度\n G是调度单位 将准备好的G分配给线程进行排队调度。 PMG 模型  P有本地LRQ M持有P才能运行G P默认与CPU核数相同 M一般 \u0026gt;= P       "
    }
,
    {
        "ref": "https://maronghe.github.io/archives/2020/leetcode/tcp/",
        "title": "",
        "section": "archives",
        "tags": null,
        "date" : "0001.01.01",
        "body": "TCP Header 默认为20字节， Header中提供各种各样的头部选项，以至于使其长度大于20字节。  连接建立超时  netstat -nat | awk '{print $6}' | sort | uniq -c | sort -n "
    }
]
